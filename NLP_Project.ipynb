{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "NLP_Project.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/shivanisingh28/Text-Summarization-using-Sequence-to-Sequence-LSTM/blob/master/NLP_Project.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cQe8_detSKha",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Import the numpy library to work with and manipulate the data\n",
        "import numpy as np\n",
        "\n",
        "# Import the pandas library to read our dataset\n",
        "import pandas as pd"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gVmcRZ4dSpci",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Summarized data\n",
        "summary = pd.read_csv('news_summary.csv', encoding='iso-8859-1')\n",
        "\n",
        "# Raw data for the respective news\n",
        "raw = pd.read_csv('news_summary_more.csv', encoding='iso-8859-1')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eR9kFltOXxXE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Take up the data in variables\n",
        "pre1 =  raw.iloc[:,0:2].copy()\n",
        "pre2 = summary.iloc[:,0:6].copy()\n",
        "\n",
        "# Concatenate the whole data in single column attribute\n",
        "pre2['text'] = pre2['author'].str.cat(pre2['date'].str.cat(pre2['read_more'].str.cat(pre2['text'].str.cat(pre2['ctext'], sep = \" \"), sep =\" \"),sep= \" \"), sep = \" \")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZFYgOBs0X3ul",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "pre = pd.DataFrame()\n",
        "\n",
        "# Concatenate text and summary in a single dataframe\n",
        "pre['text'] = pd.concat([pre1['text'], pre2['text']], ignore_index=True)\n",
        "pre['summary'] = pd.concat([pre1['headlines'],pre2['headlines']], ignore_index = True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "T6oP5qraX54l",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Regular expressions library to preprocess the data\n",
        "import re\n",
        "\n",
        "#Removes non-alphabetic characters:\n",
        "def text_strip(column):\n",
        "  for sentRow in column:\n",
        "    # Remove the tab, carriage return, newline character respectively\n",
        "    sentRow=re.sub(\"(\\\\t)\", ' ', str(sentRow)).lower()\n",
        "    sentRow=re.sub(\"(\\\\r)\", ' ', str(sentRow)).lower() \n",
        "    sentRow=re.sub(\"(\\\\n)\", ' ', str(sentRow)).lower()\n",
        "\n",
        "    # Remove _-~+. if it occurs more than one consecutively\n",
        "    sentRow=re.sub(\"(__+)\", ' ', str(sentRow)).lower()\n",
        "    sentRow=re.sub(\"(--+)\", ' ', str(sentRow)).lower()\n",
        "    sentRow=re.sub(\"(~~+)\", ' ', str(sentRow)).lower()\n",
        "    sentRow=re.sub(\"(\\+\\++)\", ' ', str(sentRow)).lower() \n",
        "    sentRow=re.sub(\"(\\.\\.+)\", ' ', str(sentRow)).lower()\n",
        "\n",
        "    # Remove <>()|&©ø\"',;?~*!\n",
        "    sentRow=re.sub(r\"[<>()|&©ø\\[\\]\\'\\\",;?~*!]\", ' ', str(sentRow)).lower()\n",
        "    \n",
        "    # Remove mailto:, \\x9*, Replace INC nums to INC_NUM, CM# and CHG# to CM_NUM\n",
        "    sentRow=re.sub(\"(mailto:)\", ' ', str(sentRow)).lower()\n",
        "    sentRow=re.sub(r\"(\\\\x9\\d)\", ' ', str(sentRow)).lower()\n",
        "    sentRow=re.sub(\"([iI][nN][cC]\\d+)\", 'INC_NUM', str(sentRow)).lower()\n",
        "    sentRow=re.sub(\"([cC][mM]\\d+)|([cC][hH][gG]\\d+)\", 'CM_NUM', str(sentRow)).lower()\n",
        "    \n",
        "    # Remove .-: at the end of words\n",
        "    sentRow=re.sub(\"(\\.\\s+)\", ' ', str(sentRow)).lower()\n",
        "    sentRow=re.sub(\"(\\-\\s+)\", ' ', str(sentRow)).lower()\n",
        "    sentRow=re.sub(\"(\\:\\s+)\", ' ', str(sentRow)).lower()\n",
        "    \n",
        "    # Remove any single characters hanging between 2 spaces\n",
        "    sentRow=re.sub(\"(\\s+.\\s+)\", ' ', str(sentRow)).lower()\n",
        "    \n",
        "    # Replace any url as such http://pqr.abc.net/search/dep123 ====> pqr.abc.net\n",
        "    try:\n",
        "      url = re.search(r'((https*:\\/*)([^\\/\\s]+))(.[^\\s]+)', str(sentRow))\n",
        "      repl_url = url.group(3)\n",
        "      sentRow = re.sub(r'((https*:\\/*)([^\\/\\s]+))(.[^\\s]+)',repl_url, str(sentRow))\n",
        "    except:\n",
        "      pass #there may be some emails with no url in them\n",
        "\n",
        "    # Remove multiple spaces\n",
        "    sentRow = re.sub(\"(\\s+)\",' ',str(sentRow)).lower()\n",
        "    \n",
        "    # Remove any single charecters hanging between 2 spaces\n",
        "    sentRow=re.sub(\"(\\s+.\\s+)\", ' ', str(sentRow)).lower()\n",
        "\n",
        "    yield sentRow"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "A39j6PXnYDab",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Data cleaninig and striping\n",
        "brief_cleaning1 = text_strip(pre['text'])\n",
        "brief_cleaning2 = text_strip(pre['summary'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FK9lBTtCYFuk",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from time import time\n",
        "import spacy\n",
        "\n",
        "# Disabling Named Entity Recognition for speed\n",
        "nlp = spacy.load('en', disable=['ner', 'parser'])\n",
        "\n",
        "#Taking advantage of spaCy .pipe() method to speed-up the cleaning process\n",
        "t = time()\n",
        "\n",
        "#Batch the data points into 5000 and run on all cores for faster preprocessing\n",
        "text = [str(doc) for doc in nlp.pipe(brief_cleaning1, batch_size=5000, n_threads=-1)]\n",
        "\n",
        "#Takes 5-6 mins\n",
        "print('Time to clean up everything: {} mins'.format(round((time() - t) / 60, 2)))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wczJKoNaYH3J",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "t = time()\n",
        "\n",
        "#Batch the data points into 5000 and run on all cores for faster preprocessing\n",
        "summary = ['_START_ '+ str(doc) + ' _END_' for doc in nlp.pipe(brief_cleaning2, batch_size=5000, n_threads=-1)]\n",
        "\n",
        "print('Time to clean up everything: {} mins'.format(round((time() - t) / 60, 2)))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xpGXOsg-YKCP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "pre['cleaned_text'] = pd.Series(text)\n",
        "pre['cleaned_summary'] = pd.Series(summary)\n",
        "\n",
        "text_count = []\n",
        "summary_count = []"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rUBsztvGYY8y",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# count the text and summary\n",
        "\n",
        "for sent in pre['cleaned_text']:\n",
        "    text_count.append(len(sent.split()))\n",
        "for sent in pre['cleaned_summary']:\n",
        "    summary_count.append(len(sent.split()))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GIKJ_K3IYbX1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "graph_df= pd.DataFrame()\n",
        "graph_df['text']=text_count\n",
        "graph_df['summary']=summary_count\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "graph_df.hist(bins = 5)\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eBMb8MnTYkjD",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Model to summarize the text between 0-50 words for Summary and 0-200 words for Text\n",
        "max_text_len = 200\n",
        "max_summary_len = 50\n",
        "\n",
        "#Select the Summaries and Text between max len defined above\n",
        "cleaned_text = np.array(pre['cleaned_text'])\n",
        "cleaned_summary = np.array(pre['cleaned_summary'])\n",
        "\n",
        "short_text = []\n",
        "short_summary = []\n",
        "\n",
        "for i in range(len(cleaned_text)):\n",
        "    if(len(cleaned_summary[i].split())<=max_summary_len and len(cleaned_text[i].split())<=max_text_len):\n",
        "        short_text.append(cleaned_text[i])\n",
        "        short_summary.append(cleaned_summary[i])\n",
        "        \n",
        "post_pre=pd.DataFrame({'text':short_text,'summary':short_summary})"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CX8Wgd7PYpsP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "post_pre.head(2)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IM_tlftnYrpq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Add sostok(start of sentence token) and eostok(end of sentence token)\n",
        "post_pre['summary'] = post_pre['summary'].apply(lambda x : 'sostok '+ x + ' eostok')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ouqfJTOSYuas",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "post_pre.head(2)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sfwgMgNOY0rh",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Get the train/test split package from sklearn for preparing our dataset to\n",
        "# train and test the model with\n",
        "from sklearn.model_selection import train_test_split\n",
        "x_tr,x_val,y_tr,y_val=train_test_split(np.array(post_pre['text']),np.array(post_pre['summary']),test_size=0.3,random_state=0,shuffle=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EiH9-vXDY3Sp",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Let's tokenize the text to get the vocab count\n",
        "from keras.preprocessing.text import Tokenizer \n",
        "from keras.preprocessing.sequence import pad_sequences"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7KwVbnfgY7SQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Prepare a tokenizer on training data for reviews\n",
        "x_tokenizer = Tokenizer(num_words=5000) \n",
        "x_tokenizer.fit_on_texts(list(x_tr))\n",
        "\n",
        "# Convert text sequences into integer sequences (i.e one-hot encodeing all the words)\n",
        "x_tr_seq    =   x_tokenizer.texts_to_sequences(x_tr) \n",
        "x_val_seq   =   x_tokenizer.texts_to_sequences(x_val)\n",
        "\n",
        "# Padding zero upto maximum length\n",
        "x_tr    =   pad_sequences(x_tr_seq,  maxlen=max_text_len, padding='post')\n",
        "x_val   =   pad_sequences(x_val_seq, maxlen=max_text_len, padding='post')\n",
        "\n",
        "# Size of vocabulary ( +1 for padding token)\n",
        "x_voc   =  len(x_tokenizer.word_index) + 1"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZzOCEsUjZBfR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Prepare a tokenizer for reviews on testing data\n",
        "y_tokenizer = Tokenizer(num_words=5000) \n",
        "y_tokenizer.fit_on_texts(list(y_tr))\n",
        "\n",
        "# Convert text sequences into integer sequences (i.e one hot encode the text in Y)\n",
        "y_tr_seq    =   y_tokenizer.texts_to_sequences(y_tr) \n",
        "y_val_seq   =   y_tokenizer.texts_to_sequences(y_val) \n",
        "\n",
        "# Padding zero upto maximum length\n",
        "y_tr    =   pad_sequences(y_tr_seq, maxlen=max_summary_len, padding='post')\n",
        "y_val   =   pad_sequences(y_val_seq, maxlen=max_summary_len, padding='post')\n",
        "\n",
        "# Size of vocabulary\n",
        "y_voc  =   len(y_tokenizer.word_index) +1"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mWKHGMVIZDuQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "ind=[]\n",
        "for i in range(len(y_tr)):\n",
        "    cnt=0\n",
        "    for j in y_tr[i]:\n",
        "        if j!=0:\n",
        "            cnt=cnt+1\n",
        "    if(cnt==2):\n",
        "        ind.append(i)\n",
        "\n",
        "y_tr=np.delete(y_tr,ind, axis=0)\n",
        "x_tr=np.delete(x_tr,ind, axis=0)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AdPxpNI1ZFvQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "ind=[]\n",
        "for i in range(len(y_val)):\n",
        "    cnt=0\n",
        "    for j in y_val[i]:\n",
        "        if j!=0:\n",
        "            cnt=cnt+1\n",
        "    if(cnt==2):\n",
        "        ind.append(i)\n",
        "\n",
        "y_val=np.delete(y_val,ind, axis=0)\n",
        "x_val=np.delete(x_val,ind, axis=0)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kJSlZ0UpypRL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "from numpy import array\n",
        "from numpy import asarray\n",
        "from numpy import zeros\n",
        "\n",
        "#Import GloVe word embeddings\n",
        "# download file form here: https://www.kaggle.com/terenceliu4444/glove6b100dtxt\n",
        "\n",
        "embeddings_dictionary = dict()\n",
        "glove_file = open('/content/glove.6B.100d.txt', encoding=\"utf8\")\n",
        "\n",
        "for line in glove_file:\n",
        "    records = line.split()\n",
        "    word = records[0]\n",
        "    vector_dimensions = asarray(records[1:], dtype='float32')\n",
        "    embeddings_dictionary [word] = vector_dimensions\n",
        "glove_file.close()\n",
        "\n",
        "#Updating the dictionary with the pre-trained GloVe embeddings.\n",
        "embedding_matrix = zeros((x_voc, 100))\n",
        "for word, index in x_tokenizer.word_index.items():\n",
        "    embedding_vector = embeddings_dictionary.get(word)\n",
        "    if embedding_vector is not None:\n",
        "        embedding_matrix[index] = embedding_vector"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JB55U9mAZKTO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from tensorflow.keras import backend as K \n",
        "import gensim\n",
        "from numpy import *\n",
        "from bs4 import BeautifulSoup\n",
        "from nltk.corpus import stopwords\n",
        "from tensorflow.keras.layers import Input, LSTM, Embedding, Dense, Concatenate, TimeDistributed\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.callbacks import EarlyStopping\n",
        "import warnings\n",
        "pd.set_option(\"display.max_colwidth\", 200)\n",
        "warnings.filterwarnings(\"ignore\")\n",
        "\n",
        "print(\"Size of vocabulary from the w2v model = {}\".format(x_voc))\n",
        "\n",
        "K.clear_session()\n",
        "\n",
        "latent_dim = 300\n",
        "embedding_dim=100\n",
        "\n",
        "# Encoder\n",
        "encoder_inputs = Input(shape=(max_text_len,))\n",
        "\n",
        "#embedding layer\n",
        "enc_emb =  Embedding(x_voc, embedding_dim, weights=[embedding_matrix], trainable=True)(encoder_inputs)\n",
        "\n",
        "#encoder lstm 1\n",
        "encoder_lstm1 = LSTM(latent_dim,return_sequences=True,return_state=True,dropout=0.5,recurrent_dropout=0.5)\n",
        "encoder_output1, state_h1, state_c1 = encoder_lstm1(enc_emb)\n",
        "\n",
        "#encoder lstm 2\n",
        "encoder_lstm2 = LSTM(latent_dim,return_sequences=True,return_state=True,dropout=0.5,recurrent_dropout=0.5)\n",
        "encoder_output2, state_h2, state_c2 = encoder_lstm2(encoder_output1)\n",
        "\n",
        "#encoder lstm 3\n",
        "encoder_lstm3=LSTM(latent_dim, return_state=True, return_sequences=True,dropout=0.5,recurrent_dropout=0.5)\n",
        "encoder_outputs, state_h, state_c= encoder_lstm3(encoder_output2)\n",
        "\n",
        "# Set up the decoder, using 'encoder_states' as initial state.\n",
        "decoder_inputs = Input(shape=(None,))\n",
        "\n",
        "#embedding layer\n",
        "dec_emb_layer = Embedding(y_voc, embedding_dim,trainable=True)\n",
        "dec_emb = dec_emb_layer(decoder_inputs)\n",
        "\n",
        "decoder_lstm = LSTM(latent_dim, return_sequences=True, return_state=True,dropout=0.5,recurrent_dropout=0.5)\n",
        "decoder_outputs,decoder_fwd_state, decoder_back_state = decoder_lstm(dec_emb,initial_state=[state_h, state_c])\n",
        "\n",
        "#dense layer\n",
        "decoder_dense =  TimeDistributed(Dense(y_voc, activation='softmax'))\n",
        "decoder_outputs = decoder_dense(decoder_outputs)\n",
        "\n",
        "# Define the model \n",
        "model = Model([encoder_inputs, decoder_inputs], decoder_outputs)\n",
        "\n",
        "model.summary()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "57e05kD2ZSmp",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model.compile(optimizer='Adam', loss='sparse_categorical_crossentropy',metrics=['accuracy'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gDSWgTrIZUn7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "es = EarlyStopping(monitor='val_loss', mode='min', verbose=1,patience=2)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aS_gQs6ZZWVc",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "history=model.fit([x_tr,y_tr[:,:-1]], y_tr.reshape(y_tr.shape[0],y_tr.shape[1], 1)[:,1:] ,epochs=10,batch_size=128, validation_data=([x_val,y_val[:,:-1]], y_val.reshape(y_val.shape[0],y_val.shape[1], 1)[:,1:]))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fUV-pFY8ZbQm",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from matplotlib import pyplot\n",
        "pyplot.plot(history.history['loss'], label='train')\n",
        "pyplot.plot(history.history['val_loss'], label='test')\n",
        "pyplot.xlabel('Epoch')\n",
        "pyplot.ylabel('Loss')\n",
        "pyplot.legend()\n",
        "pyplot.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xv_8lFxV4bmS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "pyplot.plot(history.history['accuracy'])\n",
        "pyplot.title('Model Accuracy')\n",
        "pyplot.ylabel('Accuracy')\n",
        "pyplot.xlabel('Epoch')\n",
        "pyplot.legend(['Accuracy', 'val'], loc='lower right')\n",
        "pyplot.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5rYNo_D54GXa",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "pyplot.plot(history.history['accuracy'], label='train')\n",
        "pyplot.plot(history.history['val_accuracy'], label='test')\n",
        "pyplot.xlabel('Epoch')\n",
        "pyplot.ylabel('Accuracy')\n",
        "pyplot.legend()\n",
        "pyplot.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rGOcyvyq4rwb",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "pyplot.plot(history.history['loss'])\n",
        "pyplot.title('Model Loss')\n",
        "pyplot.ylabel('Loss')\n",
        "pyplot.xlabel('Epoch')\n",
        "pyplot.legend(['Loss', 'val'], loc='lower right')\n",
        "pyplot.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Cw_HAV5CFFPj",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "history.history.keys()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "y0VKZk6cZdMh",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "reverse_target_word_index=y_tokenizer.index_word\n",
        "reverse_source_word_index=x_tokenizer.index_word\n",
        "target_word_index=y_tokenizer.word_index"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_tzBJKKGZe8x",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "encoder_model = Model(inputs=encoder_inputs,outputs=[encoder_outputs, state_h, state_c])\n",
        "\n",
        "# Decoder setup\n",
        "# Below tensors will hold the states of the previous time step\n",
        "decoder_state_input_h = Input(shape=(latent_dim,))\n",
        "decoder_state_input_c = Input(shape=(latent_dim,))\n",
        "decoder_hidden_state_input = Input(shape=(max_text_len,latent_dim))\n",
        "\n",
        "# Get the embeddings of the decoder sequence\n",
        "dec_emb2= dec_emb_layer(decoder_inputs) \n",
        "# To predict the next word in the sequence, set the initial states to the states from the previous time step\n",
        "decoder_outputs2, state_h2, state_c2 = decoder_lstm(dec_emb2, initial_state=[decoder_state_input_h, decoder_state_input_c])\n",
        "\n",
        "# A dense softmax layer to generate prob dist. over the target vocabulary\n",
        "decoder_outputs2 = decoder_dense(decoder_outputs2) \n",
        "\n",
        "# Final decoder model\n",
        "decoder_model = Model(\n",
        "    [decoder_inputs] + [decoder_hidden_state_input,decoder_state_input_h, decoder_state_input_c],\n",
        "    [decoder_outputs2] + [state_h2, state_c2])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0G_WCH50ZhY6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def decode_sequence(input_seq):\n",
        "    # Encode the input as state vectors.\n",
        "    e_out, e_h, e_c = encoder_model.predict(input_seq)\n",
        "    \n",
        "    # Generate empty target sequence of length 1.\n",
        "    target_seq = np.zeros((1,1))\n",
        "    \n",
        "    # Populate the first word of target sequence with the start word.\n",
        "    target_seq[0, 0] = target_word_index['sostok']\n",
        "\n",
        "    stop_condition = False\n",
        "    decoded_sentence = ''\n",
        "    while not stop_condition:\n",
        "      \n",
        "        output_tokens, h, c = decoder_model.predict([target_seq] + [e_out, e_h, e_c])\n",
        "\n",
        "        # Sample a token\n",
        "        sampled_token_index = np.argmax(output_tokens[0, -1, :])\n",
        "        sampled_token = reverse_target_word_index[sampled_token_index]\n",
        "        \n",
        "        if(sampled_token!='eostok'):\n",
        "            decoded_sentence += ' '+sampled_token\n",
        "\n",
        "        # Exit condition: either hit max length or find stop word.\n",
        "        if (sampled_token == 'eostok'  or len(decoded_sentence.split()) >= (max_summary_len-1)):\n",
        "            stop_condition = True\n",
        "\n",
        "        # Update the target sequence (of length 1).\n",
        "        target_seq = np.zeros((1,1))\n",
        "        target_seq[0, 0] = sampled_token_index\n",
        "\n",
        "        # Update internal states\n",
        "        e_h, e_c = h, c\n",
        "\n",
        "    return decoded_sentence"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "X5cjeGMHZml2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def seq2summary(input_seq):\n",
        "    newString=''\n",
        "    for i in input_seq:\n",
        "        if((i!=0 and i!=target_word_index['sostok']) and i!=target_word_index['eostok']):\n",
        "            newString=newString+reverse_target_word_index[i]+' '\n",
        "    return newString\n",
        "\n",
        "def seq2text(input_seq):\n",
        "    newString=''\n",
        "    for i in input_seq:\n",
        "        if(i!=0):\n",
        "            newString=newString+reverse_source_word_index[i]+' '\n",
        "    return newString"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vzD9RtQDZvxc",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "for i in range(0,100):\n",
        "    print(\"Review:\",seq2text(x_tr[i]))\n",
        "    print(\"Original summary:\",seq2summary(y_tr[i]))\n",
        "    print(\"Predicted summary:\",decode_sequence(x_tr[i].reshape(1,max_text_len)))\n",
        "    print(\"\\n\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "roeUS3cQ3eCj",
        "colab_type": "code",
        "outputId": "babf2b0a-3c9d-4841-ab9f-65ec373e03a5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "from tensorflow.keras.models import model_from_json\n",
        "#saving the model on the disk\n",
        "\n",
        "# serialize model to JSON\n",
        "model_json = model.to_json()\n",
        "with open(\"1095709_1dconv_reg.json\", \"w\") as json_file:\n",
        "    json_file.write(model_json)\n",
        "# serialize weights to HDF5\n",
        "model.save_weights(\"1095709_1dconv_reg.h5\")\n",
        "print(\"Saved model to disk\")"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Saved model to disk\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vHY-BsXd37P1",
        "colab_type": "code",
        "outputId": "e09bf62c-04d8-4259-9215-5e0f28f7b828",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        }
      },
      "source": [
        "# load json and create model\n",
        "json_file = open('1095709_1dconv_reg.json', 'r')\n",
        "loaded_model_json = json_file.read()\n",
        "json_file.close()\n",
        "loaded_model = model_from_json(loaded_model_json)\n",
        "# load weights into new model\n",
        "loaded_model.load_weights(\"1095709_1dconv_reg.h5\")\n",
        "print(\"Loaded model from disk\")\n",
        " \n",
        "# evaluate loaded model on test data\n",
        "loaded_model.compile(loss='sparse_categorical_crossentropy', optimizer='Adam', metrics=['accuracy'])\n",
        "score = loaded_model.evaluate([x_val,y_val[:,:-1]], y_val.reshape(y_val.shape[0],y_val.shape[1], 1)[:,1:], verbose=0)\n",
        "print(\"%s: %.2f%%\" % (loaded_model.metrics_names[1], score[1]*100))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Loaded model from disk\n",
            "accuracy: 84.63%\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}